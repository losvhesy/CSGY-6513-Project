{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tslearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ce31427e4395>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtslearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtslearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclustering\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKernelKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tslearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import sklearn\n",
    "import tslearn\n",
    "\n",
    "from tslearn.clustering import KernelKMeans\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import format_string\n",
    "from sklearn.manifold import TSNE\n",
    "from analysis.spark import SparkEngine\n",
    "from analysis.preprocess import extract_states\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark_engine = SparkEngine(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "alt.data_transformers.disable_max_rows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you already uploaded data to HFS\n",
    "filepath = \"/user/gw2145/integrated.csv\"\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "covid_data = spark.read.format('csv').options(header='true', inferschema='true').load(filepath)\n",
    "covid_data.createOrReplaceTempView(\"covid\")\n",
    "integrated_src_data = covid_data.toPandas()\n",
    "integrated_data = integrated_src_data.fillna(0)\n",
    "states = extract_states(integrated_data)\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you did not upload data to HFS\n",
    "local_path = \"./integrated_data.csv\"\n",
    "covid_pd = pd.read_csv(local_path)\n",
    "covid_df = spark.createDataFrame(covid_pd)\n",
    "covid_data = covid_df\n",
    "covid_data.createOrReplaceTempView(\"covid\")\n",
    "integrated_src_data = covid_data.toPandas()\n",
    "integrated_data = integrated_src_data.fillna(0)\n",
    "states = extract_states(integrated_data)\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster state data by time series k-means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.time_series import get_state_embeddings, add_cluster_info, extract_state_series, cluster_states_by_ts\n",
    "# This cell hold the functions for layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = extract_state_series(integrated_data)\n",
    "labels = cluster_states_by_ts(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = get_state_embeddings(states, labels)\n",
    "integrated_data = add_cluster_info(integrated_data, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.visualization import plot_ts_clusters\n",
    "\n",
    "plot_ts_clusters(integrated_data, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.preparation import load_state_info\n",
    "state2fips_df, populations = load_state_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from analysis.visualization import plot_map\n",
    "\n",
    "plot_map(integrated_data, state2fips_df, populations, date=\"2021-01-31\", attr=\"cases_by_population\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Load training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "df = spark_engine.join_population(covid_data, populations)\n",
    "df1 = spark_engine.add_idx(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility_metrics = [\n",
    "    \"retail_and_recreation_percent_change_from_baseline\",\n",
    "    \"grocery_and_pharmacy_percent_change_from_baseline\",\n",
    "    \"workplaces_percent_change_from_baseline\",\n",
    "    \"residential_percent_change_from_baseline\"\n",
    "]\n",
    "state_metric_correlation = spark_engine.generate_state_metric_corr(df1, states)\n",
    "state_metric_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import analysis.visualization\n",
    "importlib.reload(analysis.visualization)\n",
    "from analysis.visualization import plot_state_metric_corr, plot_corr_map\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "source_corr_matrix = []\n",
    "        \n",
    "plot_state_metric_corr(state_metric_correlation, mobility_metrics)\n",
    "# state_metric_correlation_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_corr_map(state_metric_correlation, state2fips_df, mobility_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"analysis_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !pip install nltk\n",
    "# !pip install nl4dv\n",
    "\n",
    "import importlib\n",
    "import st_nli\n",
    "importlib.reload(st_nli)\n",
    "from st_nli import NLInterface\n",
    "\n",
    "\n",
    "query_sent = \"Show the case rate in New England\"\n",
    "query_sent = \"Show the case rate on 01/31/2021 in New England\"\n",
    "query_sent = input()\n",
    "interface = NLInterface()\n",
    "interface.run(query_sent, df)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# !pip install dateparser\n",
    "# !pip install datefinder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
